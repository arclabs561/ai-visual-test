# ============================================
# Vision Language Model (VLLM) Configuration
# ============================================
# Required for visual validation and multi-modal testing
# Set at least one API key below

# Provider selection (optional - auto-detects if not set)
# Options: gemini, openai, claude
# Priority: VLM_PROVIDER env var > auto-detect from available API keys > default to gemini
VLM_PROVIDER=

# Provider-specific API keys (set at least one)
# Gemini (recommended - free tier available, cheapest)
GEMINI_API_KEY=

# OpenAI (requires paid account)
OPENAI_API_KEY=

# Anthropic Claude (requires paid account)
ANTHROPIC_API_KEY=

# Generic API key (fallback if provider-specific key not set)
# Uses provider specified in VLM_PROVIDER or defaults to gemini
API_KEY=

# ============================================
# Optional Configuration
# ============================================
# Debug mode (set to 1 to enable verbose logging)
DEBUG_VLLM=

# Cache directory (optional - defaults to system temp)
# CACHE_DIR=

# ============================================
# Notes
# ============================================
# - This package uses @arclabs561/llm-utils for text-only LLM calls
# - For visual validation, VLLM providers are required
# - Gemini is recommended for cost-effectiveness (free tier available)
# - See README.md for provider selection and pricing details
