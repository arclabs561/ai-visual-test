"""
Basic Screenshot Validation with ai-browser-test

This notebook demonstrates how to use ai-browser-test for basic
screenshot validation using Vision Language Models (VLLM).

Note: This is a conceptual example. In practice, you would need
to call the Node.js package from Python using subprocess or a bridge.
"""

import marimo

__generated_with = "0.10.6"
app = marimo.App()


@app.cell
def __():
    import os
    import json
    import subprocess
    from pathlib import Path
    import base64
    from PIL import Image
    import io
    
    # Configuration
    API_KEY = os.getenv("GEMINI_API_KEY") or os.getenv("OPENAI_API_KEY")
    SCREENSHOT_PATH = "screenshot.png"
    
    return API_KEY, Image, Path, base64, io, json, os, subprocess, SCREENSHOT_PATH


@app.cell
def __(API_KEY):
    """
    Setup: Check if API key is configured
    """
    if not API_KEY:
        print("âš ï¸  Warning: No API key found. Set GEMINI_API_KEY or OPENAI_API_KEY")
        print("   The package will run in disabled mode.")
    else:
        print("âœ… API key configured")
    
    return


@app.cell
def __(SCREENSHOT_PATH, Path):
    """
    Step 1: Check if screenshot exists
    """
    screenshot_path = Path(SCREENSHOT_PATH)
    
    if not screenshot_path.exists():
        print(f"âŒ Screenshot not found: {SCREENSHOT_PATH}")
        print("   Please provide a screenshot file.")
        screenshot_available = False
    else:
        print(f"âœ… Screenshot found: {SCREENSHOT_PATH}")
        screenshot_available = True
    
    return screenshot_available, screenshot_path


@app.cell
def __(screenshot_available, screenshot_path, base64, io, Image):
    """
    Step 2: Load and display screenshot
    """
    if screenshot_available:
        # Load image
        img = Image.open(screenshot_path)
        
        # Display image
        display(img)
        
        # Get image info
        width, height = img.size
        print(f"ðŸ“ Image size: {width}x{height} pixels")
        
        # Convert to base64 for API
        buffer = io.BytesIO()
        img.save(buffer, format='PNG')
        img_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
        
        image_info = {
            "width": width,
            "height": height,
            "base64": img_base64[:50] + "..."  # Preview only
        }
    else:
        image_info = None
    
    return height, image_info, img, width


@app.cell
def __(API_KEY, image_info, json, screenshot_path, subprocess):
    """
    Step 3: Validate screenshot using ai-browser-test
    
    This calls the Node.js package via subprocess.
    In production, you might use a proper Python bridge.
    """
    if not image_info:
        result = None
        print("â­ï¸  Skipping validation (no screenshot)")
    else:
        # Create a Node.js script to call the package
        node_script = f"""
        import {{ validateScreenshot }} from 'ai-browser-test';
        
        const result = await validateScreenshot(
            '{screenshot_path}',
            'Evaluate this screenshot for quality, accessibility, and design principles.',
            {{
                testType: 'general',
                viewport: {{ width: {width}, height: {height} }}
            }}
        );
        
        console.log(JSON.stringify(result, null, 2));
        """
        
        # Write temporary script
        script_path = Path("temp_validate.mjs")
        script_path.write_text(node_script)
        
        try:
            # Run Node.js script
            process = subprocess.run(
                ["node", str(script_path)],
                capture_output=True,
                text=True,
                env={**os.environ, "GEMINI_API_KEY": API_KEY or ""}
            )
            
            if process.returncode == 0:
                result = json.loads(process.stdout)
                print("âœ… Validation completed")
            else:
                result = {"error": process.stderr}
                print(f"âŒ Validation failed: {process.stderr}")
        except Exception as e:
            result = {"error": str(e)}
            print(f"âŒ Error: {e}")
        finally:
            # Clean up
            if script_path.exists():
                script_path.unlink()
    
    return result,


@app.cell
def __(result):
    """
    Step 4: Display validation results
    """
    import marimo as mo
    
    if result and "error" not in result:
        if result.get("enabled", True):
            score = result.get("score")
            issues = result.get("issues", [])
            assessment = result.get("assessment", "")
            reasoning = result.get("reasoning", "")
            
            # Display score
            if score is not None:
                score_color = "green" if score >= 0.8 else "orange" if score >= 0.6 else "red"
                mo.md(f"""
                ## Validation Results
                
                **Score:** <span style="color: {score_color}">{score:.2f}/1.0</span>
                
                **Provider:** {result.get("provider", "unknown")}
                **Cached:** {result.get("cached", False)}
                """)
            else:
                mo.md("## Validation Results\n\nâš ï¸ No score available")
            
            # Display issues
            if issues:
                mo.md(f"""
                ### Issues Found ({len(issues)})
                
                {chr(10).join(f"- {issue}" for issue in issues)}
                """)
            
            # Display assessment
            if assessment:
                mo.md(f"""
                ### Assessment
                
                {assessment}
                """)
            
            # Display reasoning
            if reasoning:
                mo.md(f"""
                ### Reasoning
                
                {reasoning[:500]}{"..." if len(reasoning) > 500 else ""}
                """)
        else:
            mo.md(f"""
            ## Validation Disabled
            
            {result.get("message", "API key not configured")}
            """)
    elif result and "error" in result:
        mo.md(f"""
        ## Error
        
        {result["error"]}
        """)
    else:
        mo.md("## No Results\n\nRun validation to see results.")
    
    return mo,


@app.cell
def __():
    """
    Next Steps
    
    - Try different prompts for specific evaluations
    - Test with different viewport sizes
    - Use multi-modal validation (screenshot + HTML + CSS)
    - Explore persona-based testing
    """
    return

